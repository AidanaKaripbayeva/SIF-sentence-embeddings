{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "from tempfile import gettempdir\n",
    "import zipfile\n",
    "import gensim\n",
    "import scipy.sparse\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "from numpy.linalg import solve, norm\n",
    "from numpy.random import rand\n",
    "from gensim.models import Word2Vec\n",
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "import itertools\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from glove import Glove\n",
    "from glove import Corpus\n",
    "\n",
    "rng = np.random\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "config.gpu_options.allow_growth = True #allocate dynamically \n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_download(filename, url, path):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    local_filename = os.path.join(path, filename)\n",
    "    if not os.path.exists(local_filename):      \n",
    "        local_filename, _ = urllib.request.urlretrieve(url + filename,\n",
    "                                                   local_filename)\n",
    "    statinfo = os.stat(local_filename)\n",
    "    return local_filename\n",
    "\n",
    "# Read the data into a list of strings.\n",
    "def read_data(filename):\n",
    "    \"\"\"Extract the first file enclosed in a zip file as a list of words\"\"\"\n",
    "    with zipfile.ZipFile(filename) as f:\n",
    "        data = tf.compat.as_str(f.read(f.namelist()[0]))\n",
    "    return data\n",
    "\n",
    "\n",
    "filename = maybe_download('enwik9.zip', 'http://mattmahoney.net/dc/', '/home/aidana/')\n",
    "vocabulary = read_data(filename)\n",
    "      \n",
    "words = vocabulary.split('.')\n",
    "\n",
    "# convert to lower case\n",
    "\n",
    "words = [word.lower() for word in words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "we = []\n",
    "for i in words:\n",
    "    i = i.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in i]\n",
    "\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    sen = [word for word in stripped if word.isalpha()]\n",
    "    \n",
    "    we.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(we, size=300, window=2, min_count= 50, workers=4, sg = 1, negative=5)\n",
    "#model = Word2Vec.load('text8_gensim') #load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1298288921, 1780761075)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(we, total_examples=model.corpus_count, epochs = 15) #train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('Word2Vec_enwik_300d') # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data']) + os.sep\n",
    "print(test_data_dir)\n",
    "model.evaluate_word_pairs(test_data_dir +'wordsim353.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = model.accuracy(test_data_dir + 'questions-words.txt')\n",
    "corr_num = sum([len(section[\"correct\"]) for section in acc])\n",
    "incorr_num = sum([len(section[\"incorrect\"]) for section in acc])\n",
    "print(corr_num/(corr_num+incorr_num))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
